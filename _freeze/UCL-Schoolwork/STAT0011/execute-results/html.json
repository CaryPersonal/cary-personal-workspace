{
  "hash": "7c383b0d90c88bb019f2e554a79cd2ae",
  "result": {
    "markdown": "---\ntitle: STAT0011\nsubtitle: Decision and Risk\nexecute: \n  eval: false\n---\n\n\n# [**Z Score Calculator**](https://www.calculator.net/z-score-calculator.html)\n\n# [**Normal Distribution Calculator**](https://www.hackmath.net/en/calculator/normal-distribution)\n\n# **Important Distributions**\n\n## **Continuous Distributions**\n\n### **Normal Distribution (Gaussian Distribution)**\n\n![](images/image-2146374466.png)\n\n### **Uniform Distribution**\n\n![](images/image-1370233818.png)\n\n### **Gamma Distribution**\n\n![](images/image-267642431.png)\n\n# **Copula Analysis Using R**\n\n## **Week 5 Data**\n\nRequired Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages({\n  library(VineCopula) # Copula analysis\n  library(ADGofTest) # Anderson-Darling Goodness-of-Fit test\n  library(KScorrect) # (Lilliefors-Corrected) Kolmogorov-Smirnov Goodness-of-Fit test\n  library(fGarch) # Time series analysis\n})\n```\n:::\n\n\nLoad the data and have a look:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(\"week5data.RData\")\nplot(dataset)\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nThis does not look like a sample from a bivariate normal distribution! In fact, `ret1` follows a Student-t distribution with 10 degrees of freedom (df); `ret2` follows a Student-t distribution with 6 df. Let's assume we have this information.\n\nNext we apply **Probability Integral Transform (PIT)** to `ret1` which has Student-t distribution with 10 df:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nu1 <- pstd(dataset$ret1, mean = 0, sd = 1, nu = 10)\nhist(u1)\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nImplement Kolmogorov-Smirnov test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nKStest1 <- LcKS(u1, cdf = \"punif\")\nKStest1$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3724\n```\n:::\n:::\n\n\nImplement Anderson-Darling test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nADtest1 <- ad.test(u1, null = \"punif\")\nADtest1$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       AD \n0.3243088 \n```\n:::\n:::\n\n\nThen we apply **Probability Integral Transform (PIT)** to `ret2` which has Student-t distribution with 6 df:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nu2 <- pstd(dataset$ret2, mean = 0, sd = 1, nu = 6)\nhist(u2)\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nImplement Kolmogorov-Smirnov test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nKStest2 <- LcKS(u2, cdf = \"punif\")\nKStest2$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2088\n```\n:::\n:::\n\n\nImplement Anderson-Darling test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nADtest2 <- ad.test(u1, null = \"punif\")\nADtest2$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       AD \n0.3243088 \n```\n:::\n:::\n\n\nWe **pass** the **test for uniformity** for both transformed log-returns, so we can proceed to copula modelling.\n\nUsing `BiCopSelect` function fit various copulas to the dataset and select the copula that provides the best fit based on the **AIC** criterion:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(cbind(u1, u2))\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmodel <- BiCopSelect(u1, u2, familyset = NA, selectioncrit = \"AIC\", indeptest = TRUE, level = 0.05)\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBivariate copula: Clayton (par = 1.94, tau = 0.49) \n```\n:::\n:::\n\n\nThe model of best fit is **Clayton with the estimated parameter theta = 1.94**.\n\nNext we estimate the Value-at-Risk using the **Monte Carlo simulation** approach based on copula theory:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 1800\nset.seed(0123)\nu_sim <- BiCopSim(N, family = 3, model$par) # family = 3 means Clayton\n```\n:::\n\n\nNext we apply the component-wise **Inverse Probability Integral Transform (IPIT)** to both `ret1` and `ret2`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nret1_sim <- qstd(u_sim[,1], mean = 0, sd = 1, nu = 10)\nret2_sim <- qstd(u_sim[,2], mean = 0, sd = 1, nu = 6)\n```\n:::\n\n\nNote that our selected copula model is capable of generating values of log-returns with the observed dependence structure:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,1))\nplot(dataset, ylab = \"ret2\", xlab = \"ret1\", col = \"blue\", main = \"Original log-returns\")\nplot(data.frame(ret1_sim, ret2_sim), ylab = \"ret2_sim\", xlab = \"ret1_sim\",\n     col = \"blue\", main = \"Simulated log-returns\")\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow=c(1,1))\n```\n:::\n\n\nNext, compute portfolio log-returns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nport_sim <- matrix(0, nrow = N, ncol = 1)\nVaR_sim <- matrix(0, nrow = 1, ncol = 2)\n\nport_sim <- log(1 + ((exp(ret1_sim) - 1) + (exp(ret2_sim) - 1)) * (1 / 2)) # Need to transform individual log-returns back to individual net returns, and compute portfolio net returns, finally compute portfolio log-returns.\n```\n:::\n\n\nReturn the estimated 99% and 95% Value-at-Risk estimates:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_sim <- quantile(port_sim, c(0.01, 0.05))\nvar_sim\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1%        5% \n-2.244965 -1.512537 \n```\n:::\n:::\n\n\n# **Time Series Analysis Using R**\n\n## **Week 6 Data**\n\nRequired Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages({\n  library(VineCopula) # Copula analysis\n  library(ADGofTest) # Anderson-Darling Goodness-of-Fit test\n  library(KScorrect) # (Lilliefors-Corrected) Kolmogorov-Smirnov Goodness-of-Fit test\n  library(fGarch) # Time series analysis\n  library(tseries)\n})\n```\n:::\n\n\nLoad the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(\"week6data.RData\")\nret1 <- dataset[,1]\nret2 <- dataset[,2]\n```\n:::\n\n\nUse the **Jarque--Bera test**, a [goodness-of-fit](https://en.wikipedia.org/wiki/Goodness-of-fit \"Goodness-of-fit\") test of whether sample data have the [skewness](https://en.wikipedia.org/wiki/Skewness \"Skewness\") and [kurtosis](https://en.wikipedia.org/wiki/Kurtosis \"Kurtosis\") matching a [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution \"Normal distribution\"):\n\n\n::: {.cell}\n\n```{.r .cell-code}\njarque.bera.test(ret1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tJarque Bera Test\n\ndata:  ret1\nX-squared = 54.62, df = 2, p-value = 1.379e-12\n```\n:::\n\n```{.r .cell-code}\njarque.bera.test(ret2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tJarque Bera Test\n\ndata:  ret2\nX-squared = 888.08, df = 2, p-value < 2.2e-16\n```\n:::\n:::\n\n\n### **Model for the Conditional Mean: AR Models - the Box-Jenkins Approach**\n\n#### **Step 1: Identification**\n\nReturns 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nacf(ret1, col = \"green\", lwd = 2)\npacf(ret1, col = \"green\", lwd = 2)\nacf(ret1^2, col = \"red\", lwd = 2)\npar(mfrow=c(1,1))\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nReturns 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nacf(ret2, col = \"green\", lwd = 2)\npacf(ret2, col = \"green\", lwd = 2)\nacf(ret2^2, col = \"red\", lwd = 2)\npar(mfrow=c(1,1))\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n#### **Step 2: Estimation**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- garchFit(formula = ~ arma(1,0) + garch(1,1), data = ret1, trace = F, cond.dist = \"norm\")\nmodel2 <- garchFit(formula = ~ arma(3,0) + garch(1,1), data = ret2, trace = F, cond.dist = \"norm\")\n```\n:::\n\n\nNote: this function uses **all first three lags**, not lag 3 only.\n\n#### **Step 3: Model Checking**\n\nReturns 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres1 <- residuals(model1, standardize = TRUE)\npar(mfrow = c(2, 1))\nacf(res1, col = \"green\", lwd = 2)\nacf(res1^2, col = \"red\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\nBox.test(res1, lag = 10, type = c(\"Ljung-Box\"), fitdf = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  res1\nX-squared = 8.495, df = 9, p-value = 0.4851\n```\n:::\n\n```{.r .cell-code}\nBox.test(res1^2, lag = 10, type = c(\"Ljung-Box\"), fitdf = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  res1^2\nX-squared = 11.657, df = 9, p-value = 0.2333\n```\n:::\n\n```{.r .cell-code}\nmodel1@fit$ics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      AIC       BIC       SIC      HQIC \n0.5658129 0.5798152 0.5658005 0.5709543 \n```\n:::\n\n```{.r .cell-code}\nu1 <- pnorm(res1, mean = 0, sd = 1)[4:length(ret1)]\nhist(u1)\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-21-2.png){width=672}\n:::\n:::\n\n\nFurther distributional checks\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Kolmogorov-Smirnov test\nKStest1 <- LcKS(u1, cdf = \"punif\")\nKStest1$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.418\n```\n:::\n\n```{.r .cell-code}\n#Anderson-Darling test\nADtest1 <- ad.test(u1, null = \"punif\")\nADtest1$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       AD \n0.4202428 \n```\n:::\n:::\n\n\nReturns 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres2 <- residuals(model2, standardize = TRUE)\npar(mfrow = c(2, 1))\nacf(res2, col = \"green\", lwd = 2)\nacf(res2^2, col = \"red\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\nBox.test(res2, lag = 10, type = c(\"Ljung-Box\"), fitdf = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  res2\nX-squared = 4.4836, df = 7, p-value = 0.7227\n```\n:::\n\n```{.r .cell-code}\nBox.test(res2^2, lag = 10, type = c(\"Ljung-Box\"), fitdf = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  res2^2\nX-squared = 7.5536, df = 7, p-value = 0.3736\n```\n:::\n\n```{.r .cell-code}\nmodel2@fit$ics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     AIC      BIC      SIC     HQIC \n2.011268 2.030871 2.011244 2.018466 \n```\n:::\n\n```{.r .cell-code}\nu2 <- pnorm(res2, mean = 0, sd = 1)[4:length(ret2)]\nhist(u2)\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-23-2.png){width=672}\n:::\n:::\n\n\nFurther distributional checks\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Kolmogorov-Smirnov test\nKStest2 <- LcKS(u2, cdf = \"punif\")\nKStest2$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6628\n```\n:::\n\n```{.r .cell-code}\n#Anderson-Darling test\nADtest2 <- ad.test(u2, null = \"punif\")\nADtest2$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      AD \n0.880416 \n```\n:::\n:::\n\n\n#### Misspecification Example 1: Using AIC and BIC\n\nLet's deliberately choosing the \"wrong\" AR(1) model instead of AR(3) model to show that the AIC and BIC are indeed helpful model selection criteria!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2b <- garchFit(formula = ~arma(1,0) + garch(1,1), data = ret2, trace = F, cond.dist = \"norm\")\nres2b <- residuals(model2b, standardize = TRUE)\n\npar(mfrow = c(1, 2))\nacf(res2b, col = \"green\", lwd = 2)\nacf(res2b^2, col = \"red\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\n\nBox.test(res2b, lag = 10, type = c(\"Ljung-Box\"), fitdf = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  res2b\nX-squared = 784.15, df = 9, p-value < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nBox.test(res2b^2, lag = 10, type = c(\"Ljung-Box\"), fitdf = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBox-Ljung test\n\ndata:  res2b^2\nX-squared = 90.379, df = 9, p-value = 1.332e-15\n```\n:::\n\n```{.r .cell-code}\nu2b <- pnorm(res2b, mean = 0, sd = 1)\nhist(u2b)\n```\n\n::: {.cell-output-display}\n![](STAT0011_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#Kolmogorov-Smirnov test\nKStest2b <- LcKS(u2b, cdf = \"punif\")\nKStest2b$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3402\n```\n:::\n\n```{.r .cell-code}\n#Anderson-Darling test\nADtest2b <- ad.test(u2b, null = \"punif\")\nADtest2b$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       AD \n0.4864833 \n```\n:::\n:::\n",
    "supporting": [
      "STAT0011_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}