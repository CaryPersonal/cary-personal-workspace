[
  {
    "objectID": "transition-from-rmarkdown.html",
    "href": "transition-from-rmarkdown.html",
    "title": "Transition from RMarkdown",
    "section": "",
    "text": "You may already have workflows in RMarkdown and are interested in transitioning to Quarto. There’s no hurry to migrate to Quarto. Keep using Rmarkdown and when you’re ready the migration will be fine.\nHere are some notes as we migrate RMarkdown sites and books.\nTODO: translating R code chunks"
  },
  {
    "objectID": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "href": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Bookdown to Quarto",
    "text": "Bookdown to Quarto\nConverting a Bookdown book to Quarto is slightly more involved than converting a website. A book has chapters whose order must be defined, and likely has citations and cross-refs. Still, conversion is not that hard.\nWe got some practice converting from Bookdown to Quarto by helping Gavin Fay convert his lab’s fantastic onboarding documentation, the Faylab Lab Manual. Here’s the GitHub view before and after.\nOur best first reference material for this was Nick Tierney’s Notes on Changing from Rmarkdown/Bookdown to Quarto. Nick shares some scripts in that post to automate some changes. In our case, the book was small enough that we made all changes manually. Quarto documentation was indispensable.\n\nExperimenting in a low-risk environment\nWe forked a copy of the Faylab Lab manual to the Openscapes organization, and worked in a branch so we could make changes relatively risk-free. We could always fork a new copy of the original if we “broke” something. (Caution: the default when making a pull request from a fork is to push changes to the original upstream repo, not your fork and it does this without warning if you have write-access to that repo.) With local previews it’s easy to test / play with settings to see what they do. We tended to make a change, Preview, then compare the look and functionality of the book to the original. It was helpful to comment out some elements of the configuration file _output.yml after their counterparts had been added to the Quarto configuration file _quarto.yml, or to confirm they were no longer needed, before making the drastic move of deleting them.\n\n\nThe conversion\nHere are the main steps to convert the Faylab Lab manual from Bookdown to Quarto.\nCreate new empty file called _quarto.yml and add book metadata there. The screenshots below\nSet project type as book.\nMove metadata out of index.qmd and into _quarto.yml. Title, author, and publication date were in index.qmd with date set using date: \"Last updated:r Sys.Date()\". Now these are in _quarto.yml with date set using date: last-modified. Note that having R code would require you to adjust code chunk options in the Quarto style (#|). This tripped us up a bit; see GitHub Actions.\nMove chapters listing out of _bookdown.yml and into _quarto.yml.\nAdd page footer to _quarto.yml.\nHere’s what ours looked like when we finished the steps above (_quarto.yml).\n\n\n\n\n\n\n_quarto.yml contents\n\n\n\n\n\n\n\nFaylab Lab Manual\n\n\n\n\n\nChange insertion of images from html style to Quarto style. (Note Quarto calls them “figures”, not “images”.) The following snippet will insert the GitHub octocat logo in a page:\n![](https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png){fig-align=\"left\" width=\"35px\"}\nChange all filename extensions .Rmd -> .qmd (you could Preview after this change and see that the book looks the same). Note that Quarto works with .Rmd files just as well as it does .qmd, so this change is not urgent. In fact, if you have a lot of R code in your .Rmds (unlike the Faylab Lab Manual), there will be additional tinkering needed to make the code chunks happy.\n\n\nCitations\nThe Faylab Lab Manual cited two papers, presenting us with an opportunity to see how easy it is to add references to a Quarto book. Briefly, in the Visual Editor, Insert > Citation > DOI. Pasting the DOI or its full URL, we can insert the citation. This automatically creates a references.bib file and adds the full citations at the bottom of the chapter page (watch demo). In July 2022, we had to manually add a ## References heading, but this may not be necessary in future Quarto updates.\n\n\n\n\n\n\nInsert citation via its DOI using RStudio Visual Editor\n\n\n\n\n\n\n\n\n\n\nPublishing notes\nIf the book’s output is strictly html, there’s no need to specify output-dir in _quarto.yml. The output directory default is _book/, which is what we’d like. If we wanted other types of output like like PDF or EPUB, etc. those single file outputs are also written to the output-dir (Quarto docs).\nIf you currently have a docs/ folder, delete it.\nUpdate .gitignore to ignore _book/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_book/\nOnce all is settled, delete _output.yml.\nOnce the Openscapes fork was fully reviewed, we made a pull request from that to the main branch of the book’s repo. Once that was merged, we set up GitHub Actions to render the book. (TODO: instructions for GitHub Actions)\n\n\nGitHub Actions\nThis book was mostly prose and screenshots without any R code. This made the conversion from RMarkdown to Quarto likely more straightforward than if you also needed to adjust code chunk options in the quarto style (#|). Our initial GitHub Action to render the converted Faylab Lab Manual failed because we had a piece of R code - even though the code was commented out! This was resolved when we deleted the line."
  },
  {
    "objectID": "transition-from-rmarkdown.html#distill-to-quarto",
    "href": "transition-from-rmarkdown.html#distill-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Distill to quarto",
    "text": "Distill to quarto\nWe transitioned our events site from distill to quarto in May 2022 (github view before and after). We followed excellent notes and examples from Nick Tierney and Danielle Navarro.\nAfter we had changed all the files, the Build tab in the RStudio IDE still showed “Build website” rather then “Render Website” and “Preview Website”, and would error when we pushed them (because that button was expecting a distill site, not a quarto site). To fix this, we updated the .Rproj file. Clicking on the .Rproj file in the RStudio IDE will open a dialog box where you can click things you want (you can also open these in a text editor or from the GitHub website to see the actual text). To fix this situation with the Build tab: Project Options > Build Tools > Project Build Tools > None.\nLooking at files /posts/_metadata.yml and _quarto.yml helps see where things are defined. For example, to make event post citations appear, we added citation: true to /posts/_metadata.yml and in _quarto.yml under the website key we set site-url: https://openscapes.github.io/events. We deleted footer.html used with distill because footer is now defined in quarto.yml.\n\nPublishing notes\n\nBackground: Our distill site had been set up to output to a docs folder, and had GitHub Settings > Pages set to look there rather gh-pages branch. (Julie note: this was a new-to-me capability when we set up the events distill site in Spring 2021 so I had forgotten that was an option). We’ve inititally kept this same set-up for now with our events page in _quarto.yml: output-dir: docs. However, this is sub-optimal; better to not have to commit and push these files but to instead have a GitHub Action generate them upon a commit. So the following is what we did -\n\nDon’t specify output-dir in _quarto.yml. The output directory default is _site/, which is what we’d like.\nIf you currently have a docs/ folder (like we did as we were experimenting), delete it.\nUpdate .gitignore to ignore _site/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_site/\nPush these changes, merge into main.\nOn GitHub.com, in your repo, set up GitHub publishing\nFollow instructions from the explore and setup chapter."
  },
  {
    "objectID": "transition-from-rmarkdown.html#troubleshooting",
    "href": "transition-from-rmarkdown.html#troubleshooting",
    "title": "Transition from RMarkdown",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nGitHub Action fails, says you need RMarkdown but you don’t have R code!\nAnd you changed all .Rmds to .qmds!\nYou likely have a few setup code chunks from RMarkdown, that look like this:\n{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\nYou can find them by opening each of your files and having a look, or use GitHub’s search for the keyword knitr"
  },
  {
    "objectID": "learning-more.html",
    "href": "learning-more.html",
    "title": "Learning more",
    "section": "",
    "text": "An excellent overview: Reproducible authoring with Quarto - Mine Çetinkaya-Rundel, Feb 2022 - slides, youtube\nA Quarto tip a day in June 2022, from Mine Çetinkaya-Rundel.\n\n\n\nOpenscapes Champions Lessons Series\nOpenscapes Approach Guide\n\nNASA Earthdata Cloud Cookbook\n\nSee many more examples at the quarto gallery!\n\n\n\nAre you making onboarding documentation? Check out The Fay Lab Manual (now in Quarto!) for inspiration on structure - you could also start there and make it your own."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cary’s Personal Workspace",
    "section": "",
    "text": "Important DDLs\n\n\n\n\n\n\n\nSubject\nDue Date\n\n\n\n\nMATH0050 Exercise Set A\n23:59, Monday, 20 February 2023\n\n\nSTAT0023 ICA1 Take-home Component\n12:00 Noon, Monday, 20 February 2023\n\n\nSTAT0024 Coursework 1\n16:00, Tuesday, 21 February 2023\n\n\nCambridge MPhil in Management Application\n23:59, Friday, 24 February 2023"
  },
  {
    "objectID": "UCL-Schoolwork/index.html",
    "href": "UCL-Schoolwork/index.html",
    "title": "UCL Schoolwork",
    "section": "",
    "text": "UCL Portico"
  },
  {
    "objectID": "UCL-Schoolwork/MATH0050.html",
    "href": "UCL-Schoolwork/MATH0050.html",
    "title": "MATH0050 Review Note",
    "section": "",
    "text": "The symbols which we will use to construct our language consist of:"
  },
  {
    "objectID": "UCL-Schoolwork/STAT0023.html",
    "href": "UCL-Schoolwork/STAT0023.html",
    "title": "STAT0023",
    "section": "",
    "text": "Required Packages\n\nlibrary(Hmisc)\nlibrary(RColorBrewer)\nlibrary(ggplot2)\nlibrary(maps)\nlibrary(robustbase)\n\n\n\n\n\n\n\n\n\n\nNA (Not Available): missing values; NaN (Not a Number): illegal operations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies.data <- read.table(\"galapagos.dat\", header = TRUE)\n\nWhat is the name of the (smallest) / (second largest) Galapagos island in the dataset?\n\n## the smallest\nrownames(species.data)[which.min(species.data$Area)]\n## the second largest\nrownames(species.data)[order(species.data$Area, decreasing = TRUE)[2]]\n\nHow many plant species are there in total on the second largest Galapagos island in the dataset?\n\nspecies.data$Species[order(species.data$Area, decreasing = TRUE)[2]]\n\nWhat is the name of the island with a value of 25 for the Elevation variable?\n\nrownames(species.data)[species.data$Elevation == 25]\n\nHow many islands have fewer than 25 species in total?\n\nsum(species.data$Species < 25)\n\nWhat is the estimated slope in a linear regression of Area upon Scruz?\n\nModel <- lm(Area ~ Scruz, data = species.data)\nsummary(Model)\nprint(Model$coefficients, digits = 8)\n\n\n\n\n\niris <- iris\n\nWhat is the mean of the petal widths for all of the flowers in the dataset?\n\nmean(iris$Petal.Width)\n\nWhat is the mean of the petal widths for all of the “setosa” flowers in the dataset?\n\nmean(iris$Petal.Width[iris$Species == \"setosa\"])\n## or\ntapply(iris$Petal.Width, INDEX = iris$Species, FUN = mean)\n\nConsidering the petal lengths of the flowers, which of the three species has the largest standard deviation?\n\ntapply(iris$Petal.Length, INDEX = iris$Species, FUN = sd)\n\nWhat is the 40th percentile of the petal lengths for all of the flowers in the dataset?\n\nprint(quantile(iris$Petal.Length, probs = 0.4), digits = 8)\n\nConsidering the petal lengths of the flowers, which of the three species has the largest 90th percentile?\n\ntapply(iris$Petal.Length, INDEX = iris$Species, FUN = quantile, probs = 0.9)\n\nCarry out a two-tailed t test, assuming equal variances, for a difference between the population mean petal widths for “versicolor” and “virginica” flowers.\n\nresult <- t.test(iris$Petal.Width[iris$Species == \"versicolor\"],\n                 iris$Petal.Width[iris$Species == \"virginica\"],\n                 var.equal = TRUE)\nprint(result, digits = 8)\n\nCarry out an F test of the null hypothesis that the population variance of sepal lengths is the same for flowers of “setosa” and “virginica” species.\n\nresult <- var.test(iris$Sepal.Length[iris$Species == \"setosa\"],\n                   iris$Sepal.Length[iris$Species == \"virginica\"])\nprint(result, digits = 8)\n\nTo three decimal places, what is the lower limit of a 90% confidence interval for the difference between the population mean petal widths for “versicolor” and “virginica” flowers?\n\nresult <- t.test(iris$Petal.Width[iris$Species == \"versicolor\"],\n                 iris$Petal.Width[iris$Species == \"virginica\"],\n                 var.equal = TRUE,\n                 conf.level = 0.90)\nprint(result, digits = 8)\n\n\n\n\n\n\nx <- seq(-2, 2, 0.05)\nx2 <- x^2\nx3 <- x^3\nplot(x, x2)\nlines(x, x3, lwd = 2, col = \"red\")\n\n\n\n\nChickWeight <- ChickWeight\n\n\n\n\n\nCO2 <- CO2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niris <- iris\n\n\n\n\nModel <- lm(Petal.Length ~ Species - 1, data = iris)\nsummary(Model)\n\nThe coefficient estimates in the above model (no intercept) are just the sample means.\n\n\n\n\nModel <- lm(Petal.Length ~ Species, data = iris)\nsummary(Model)\n\nThe intercept in the above model (intercept included) is the Setosa sample mean. The coefficient estimates are the differences between the respective means and the Setosa mean.\n\n\n\n\nModel <- lm(Petal.Length ~ Species, data = iris, contrasts = list(Species = \"contr.sum\"))\nsummary(Model)\n\nSpecies 1: Setosa\nSpecies 2: Versicolor\nSpecies 3: Virginica\nThe intercept in the above model (“sum to zero” constraint) is the overall mean petal length for all the iris flowers. The coefficients represent the differences between the respective means and the overall mean.\n\n\n\n\nModel <- lm(Petal.Length ~ Species + Sepal.Length, data = iris)\nsummary(Model)\n\nThe intercept in the above model is the expected petal length for Setosa when the sepal length is zero.\n\n\n\n\nModel <- lm(Petal.Length ~ Species + Sepal.Length + Species:Sepal.Length, data = iris)\nsummary(Model)\n\nThe main effect coefficients for Versicolor and Virginica represent differences relative to Setosa. Two additional coefficients for the interactions represent differences in the slopes of the Petal.Length:Sepal.Length relationship for these two species, relative to the slope for Setosa flowers.\nNote: Interactions have nothing to do with correlations between covariates: rather, they relate to the way in which the relationship between one covariate and the response varies with another covariate.\n\n\n\n\n\nload(\"UStemps.rda\")\nustemp$longitude <- -ustemp$longitude\n\n\n\n\nModel1 <- lm(min.temp ~ latitude + longitude, data = ustemp)\nsummary(Model1)\n\n\n\n\n\nModel2 <- lm(min.temp ~ latitude + longitude + I(latitude^2) + I(longitude^2) + latitude:longitude, data = ustemp)\nsummary(Model2)\n\n\n\n\npar(mfrow = c(2,2),\n    mar = c(3,3,2,2),\n    mgp = c(2,0.75,0))\nplot(Model2, which = 1:4)\n\nCook’s Distance plot shows three observations that may be influential, they are:\n\nustemp[c(5, 13, 52), ]\n## 5: Los Angeles, CA\n## 13: Miami, FL\n## 52: Seattle, WA\n\n\n\n\n\n\nModel2Rob <- lmrob(min.temp ~ latitude + longitude + I(latitude^2) + I(longitude^2) + latitude:longitude, data = ustemp)\nsummary(Model2Rob)\n\nNote: the purpose of robust estimation is to try and include all of the observations, but to limit the extent to which any individual observation can influence the fit.\n\n\n\n\n\n\n\nThe main things that can result in incorrect standard errors are non-constant variance and dependence between residuals\n\nSystematic structure in mean residuals\n“Residuals vs Fitted Values” plot, or “Residuals vs Covariates” plot.\nSuch structure indicates that the modelled representation of the regression function is inadequate. Whether this matters is context-specific: you may decide, for example, that the residuals are all so small that your model is already predicting well enough.\nNon-constant variance\n“Residuals vs Fitted Values” plot may exhibit a “funnel” shape (i.e. the residual variance seems higher at one end than the other).\n“Scale-Location” plot: the absolute residuals tend to be larger at one end than the other.\nIn this case, the least-squares estimates are not fully efficient (i.e. you’re not making the best use of your data), and the reported standard errors will be incorrect — as will the results of any hypothesis tests and confidence interval calculations.\nNon-normal residuals\n“Normal Q-Q plot”: the residuals don’t fall roughly on a straight line.\nThis is not critical in large samples, the exception is where you want to calculate prediction intervals for future observations: these will only be accurate if the future observations do indeed have an approximate normal distribution.\nLack of independence\nCommon situations in which it might be a problem are when data are collected at successive time points, or at a collection of spatial locations. Although none of the ‘standard’ plots is designed to check for this, lack of independence can lead to apparent structure in some of the residual plots. For example, if observations are collected sequentially in time and successive residuals are highly correlated, this can give the appearance of curvature in the “Residuals vs Fitted Values” plot: the curvature is not due to a nonlinear relationship between response and covariates, but simply due to the fact that neighbouring residuals are similar to each other because they are correlated.\n\n\n\n\nRule-of-thumb: observation influential if Cook’s distance exceeds \\(\\frac{8}{n-2k}\\), where k is the number of coefficients estimated.\n\n\n\n\nTransform the response variable and / or covariate (but only if the resulting model makes scientific sense). Sometimes, a relationship can be made more linear by taking logs or square roots of one or more quantities; transforming the response variable can also help to make the residual variance more constant, and to make the assumption of normality more reasonable. Don’t take logs (or square roots) of quantities that could be negative, though!\nAdd additional terms to the model. For the temperature data for example, you might consider extending the quadratic model to include third-degree terms in latitude and longitude; or additional covariates such as altitude if these were available.\nIf the diagnostics suggest that the residual variance is related to the fitted values (e.g. the ‘residuals versus fitted values’ plot has a funnel shape) and there is good reason to suspect that the responses follow non-normal distributions (e.g. because they are counts, so that Poisson distributions might be more appropriate) then a more general class of models may be appropriate — such as generalized linear models (GLMs).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReturn TRUE if there is at least one strictly negative value in a vector x, and FALSE otherwise.\n\nany(x<0)\n\nExtract the elements of a vector x that are both (i) strictly positive (ii) divisible by 10.\n\nx[x>0&x%%10==0]\n\nExtract the rows of a matrix or data frame y for which the corresponding elements of a vector x are non-negative, where x is a vector with length equal to the number of rows of y.\n\ny[x>=0,]\n\nExtract the elements of a vector y for which the corresponding elements of x are strictly negative.\n\ny[x<0]\n\n\n\n\nCreate a function to approximate an integral using the trapezium rule with equally spaced x values.\n\ntrapezium <- function(v, a, b) {\n  n <- length(v) - 1\n  h <- (b - a) / n\n  intv <- (h / 2) * (sum(v) + sum(v[2 : n]))\n  intv\n}\n\nUse the above function to evaluate the integral \\(\\int_{1}^{5}arctan(x)dx\\) with 39 evaluation points (i.e. so that the input vector v has 39 elements).\n\ntrapezium(atan(seq(1, 5,length.out = 39)), 1, 5)\n\n\n\n\n\n\n\n\n\n\nCreate a QuarticMin() function to minimise function \\(h(x)=4x^2+5x+3\\), with starting value \\(x_0=-3\\).\n\nQuarticMin <- function(x0, tol = 1e-6, MaxIter = 100, Verbose = TRUE) {\n  x <- x0\n  Iter <- 0\n  dh.dx <- (8 * x) + 5 # First derivative\n  RelChange <- Inf\n  while (abs(dh.dx) > tol & abs(RelChange) > tol & Iter < MaxIter) {\n    if (Verbose) {\n      cat(paste(\"Iteration\",Iter,\":   Estimate =\",signif(x,5),\n                \"    Gradient = \",signif(dh.dx,5),\"\\n\"))\n    }\n    x.old <- x\n    d2h.dx2 <- 8 # Second derivative\n    x <- x - (dh.dx / d2h.dx2)\n    dh.dx <- (8 * x) + 5 # First derivative\n    RelChange <- (x-x.old) / x.old\n    Iter <- Iter + 1\n  }\n  if (Verbose) cat(\"---\\n\")\n  hmin <- (4 * x^2) + (5 * x) + 3 # Original\n  list(x=x, hx=hmin, gradient=dh.dx, N.iter=Iter)\n}\n\nQuarticMin(-3)\n\nNote: In Iteration n, Estimate = \\(x_{n}\\).\n\n\n\nCreate a tploglik() function to returns the negative log likelihood of a truncated Poisson distribution, up to a constant.\n\ntploglik <- function(theta, y) {\n  n <- length(y)\n  ybar <- mean(y)\n  n * (theta - (ybar * log(theta)) + log(1 - exp(-theta)))\n}\n\nTruncated Poisson Distribution Data\n\nTPdata <- rep(1:14, c(97, 164, 242, 182, 154, 83, 44, 19, 9, 7, 2, 0, 0, 1))\n\nUse nlm() and tploglik() functions to find the maximum likelihood estimate of \\(\\theta\\) together with its estimated standard error. Use the sample mean of the original 1004 values as the starting point for nlm().\n\nTP.fitted <- nlm(tploglik, mean(TPdata), y = TPdata, hessian = TRUE)\n\n\n## The MLE of theta\nTP.fitted$estimate\n## Estimated Standard Error of the MLE\n1 / sqrt(TP.fitted$hessian)\n\n\n\n\nData\n\nNLSdata <- read.table(file = \"nls2.dat\", header = TRUE)\n\nFit a linear model regressing log(Y) on x\n\nModel_Log <- lm(log(Y) ~ x, data = NLSdata)\nsummary(Model_Log)\n\nsumsqerr() function to compute sum of squared errors\n\nsumsqerr <- function(theta, x, Y) {\n  beta0 <- theta[1]\n  beta1 <- theta[2]\n  mu <- beta0 * exp(beta1 * x)\n  sum((Y - mu)^2)\n}\n\nFor your nonlinear model, what is the sum of squared errors for the parameter values \\(\\beta_0=1.4\\), \\(\\beta_1=-0.1\\)?\n\nsumsqerr(c(1.4, -0.1), x = NLSdata$x, Y = NLSdata$Y)\n\nTry fitting your nonlinear model using nlm(), with starting values \\(\\beta_0=-0.8\\) and \\(\\beta_1=-0.6\\). Compare the minimised sum of squares with the value that you obtained in the workshop starting from \\(\\beta_0=1.3\\) and \\(\\beta_1=-0.3\\). Has nlm() located (approximately) the same minimum this time?\n\nNLS.fit1 <- nlm(sumsqerr, c(-0.8, -0.6), x = NLSdata$x, Y = NLSdata$Y, hessian = TRUE)\nNLS.fit2 <- nlm(sumsqerr, c(1.3, -0.3), x = NLSdata$x, Y = NLSdata$Y, hessian = TRUE)\n\nTry fitting the model using nlm(), with starting values \\(\\beta_0=0.2\\) and \\(\\beta_1=0.4\\). At the estimated minimum, what is the (2, 2) element of the Hessian matrix of the sum of squares?\n\nNLS.fit3 <- nlm(sumsqerr, c(0.2, 0.4), x = NLSdata$x, Y = NLSdata$Y, hessian = TRUE)\nNLS.fit3$hessian[2, 2]"
  },
  {
    "objectID": "Tools-and-Tips.html",
    "href": "Tools-and-Tips.html",
    "title": "Tools and Tips",
    "section": "",
    "text": "GraphicsVideosVoices\n\n\nUnsplash: Beautiful free images & pictures.\nICONS8: Collections of good icons."
  },
  {
    "objectID": "Tools-and-Tips.html#apple-products",
    "href": "Tools-and-Tips.html#apple-products",
    "title": "Tools and Tips",
    "section": "Apple Products",
    "text": "Apple Products\n\nMac\n\niCloud\nIf iCloud gets stuck during the uploading process (never finish uploading), open the terminal and try the following:\n\n\nTerminal\n\nkillall bird\nkillall cloudd\n\nThe codes above will terminate the core process of file synchronization, and the process will start again automatically after a few seconds.\n\n\n\niPhone\n\n截屏选择\"拷贝并删除\"后，键盘卡死\n只需要再随意截屏一次即可，上一张拷贝了的截屏仍然会在剪贴板里，且可正常粘贴。"
  }
]